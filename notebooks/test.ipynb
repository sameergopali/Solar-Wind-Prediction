{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from preporcessing import TorchStandardScaler\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import random_split\n",
    "from dataloader import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14569"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX = pd.read_pickle('../data/processed/meanX.pkl').to_numpy()\n",
    "dfy = pd.read_pickle('../data/processed/meanY.pkl').to_numpy()\n",
    "\n",
    "dfX_torch = torch.from_numpy(dfX.astype(np.float32))\n",
    "dfX_torch.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.1916e-01, -6.2164e-01,  4.9645e-01,  1.4198e+06, -4.9113e+04,\n",
       "          -8.0033e+03, -4.0135e+02,  7.5098e+04,  1.3036e+05, -1.1548e+04,\n",
       "           4.0135e+04]]),\n",
       " tensor([[3.3085e+00, 3.4537e+00, 2.6056e+00, 3.3296e+04, 1.6937e+05, 9.8403e+04,\n",
       "          7.5670e+01, 5.9771e+04, 2.5072e+04, 4.6858e+04, 9.6293e+03]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler  = TorchStandardScaler()\n",
    "scaler.fit(dfX_torch)\n",
    "scaler.mean, scaler.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7139"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx,test_idx,val_idx=random_split(dfX_torch, [0.49,0.3,0.21], generator=torch.Generator().manual_seed(1))\n",
    "len(train_idx.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, fc_layers, device, dropout=0) -> None:\n",
    "        super(LSTM, self).__init__() \n",
    "        self.device=device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers =  num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,batch_first =True, dropout=dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.ModuleList()\n",
    "        for layer in fc_layers:\n",
    "            self.fc.append(nn.Linear(hidden_size,layer))\n",
    "            self.fc.append(nn.BatchNorm1d(layer))\n",
    "            self.fc.append(nn.ReLU())\n",
    "        self.fc.append(fc_layers[-1],1)\n",
    "\n",
    "       \n",
    "    def forward(self,x):\n",
    "        h0  =  torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device).requires_grad_()\n",
    "        c0  =  torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device).requires_grad_()\n",
    "\n",
    "        out, (hout,_) =  self.lstm(x,(h0,c0))\n",
    "        #out = self.activation(out[:,-1,:])\n",
    "        if self.debug:\n",
    "            print(f\"out= {out[:,-1,:]}, {hout.shape},hidden= {hout.view(-1, self.hidden_size)}\")\n",
    "\n",
    "        for layers in self.fc:\n",
    "            out = self.fc(out)\n",
    "        #out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b28b220f449c9d722e018aff2a16f7d190e45d446fc4e09783419a433be31837"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
