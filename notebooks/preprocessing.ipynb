{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing steps:\n",
    "- There is header in between data samples in csv files, so we have to remove them.\n",
    "- The delay value is same for 80 time samples\n",
    "- First, make sure that each csv file contain time sample with 80 time samples\n",
    "- Next, check if any field is null or not. If null if found, remove.\n",
    "- We remove headers, timestamp and delay information and save it as target_X file\n",
    "- We save single delay information in the target_Y file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_files(path):\n",
    "    if os.path.exists(path):\n",
    "        files = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "        return files \n",
    "    else:\n",
    "        print(\"Path not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check files if 80 samples are present between header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_samples(files):\n",
    "    lookup = 'time_ti'\n",
    "    n_total = 0\n",
    "    for f in files:\n",
    "        with open(f) as file:\n",
    "            n_samples = 80\n",
    "            for line_num, line in enumerate(file,1):\n",
    "                if lookup in line:\n",
    "                    if n_samples < 80:\n",
    "                        print(f'less than 80 samples at: {f} in line_header:{header_line}') \n",
    "                    elif n_samples == 80:\n",
    "                        pass\n",
    "                        #print('80 samples ok')\n",
    "                    elif n_samples > 80:\n",
    "                        print(f'greater than 80 samples at: {f} in line_header:{header_line}')\n",
    "                    n_samples=0\n",
    "                    header_line = line_num\n",
    "                else:\n",
    "                    n_samples += 1  \n",
    "                    n_total +=1\n",
    "                if n_samples > 80:\n",
    "                    print(f'greater than 80 samples at: {f} in line_header:{header_line}')\n",
    "                if line in ['\\n', '\\r\\n']:\n",
    "                    print(f'empty lines in {f} at line_num:{line_num}') \n",
    "            last_line =  line_num\n",
    "            if(last_line - header_line > 80 ):\n",
    "                print(f'greater than 80 samples at: {f} in line_header:{header_line}')\n",
    "            elif(last_line - header_line < 80):\n",
    "                print(f'less than 80 samples at: {f} in line_header:{header_line}')\n",
    "        #print(f'last line number {last_line}')\n",
    "    print(f'total samples is {n_total}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples is 1800880\n"
     ]
    }
   ],
   "source": [
    "data_path= '../data/raw/Updated_data/ACE_data/'\n",
    "files =  list_of_files(data_path)\n",
    "check_samples(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop group if na is present in any field\n",
    "\n",
    "def dropgroup(df):\n",
    "    n_samples = 80\n",
    "    return df.groupby(np.arange(len(df))//n_samples).filter(lambda g: g.isnull().any().any() < 1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "### Create mean of Dataframe\n",
    "def get_meandf(df):\n",
    "    n_samples = 80\n",
    "    return df.groupby(np.arange(len(df))//n_samples).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_csv(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    df = df[df.time_ti.astype(str).str.contains('time_ti') == False].astype('float32')\n",
    "    df =  dropgroup(df)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_csv(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df = df[df.time_ti.astype(str).str.contains('time_ti') == False].astype('float32')\n",
    "    except AttributeError as e:\n",
    "        print(f'Attribute error in {filepath}')\n",
    "    except Exception as e:\n",
    "        print (f'Exception handling file {filepath}')\n",
    "    return df\n",
    "\n",
    "def pre_process(df):\n",
    "    target =  df['Delay']\n",
    "    df = df.drop(columns=['time_ti', 'Delay'])\n",
    "    return df, target\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataframe for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df(df):\n",
    "    n_samples=80\n",
    "    n_nan = 0 \n",
    "    for g, dataframe in df.groupby(np.arange(len(df))//n_samples):\n",
    "        assert dataframe.shape[0] == n_samples\n",
    "        if dataframe.isnull().any().any():\n",
    "            n_nan +=1\n",
    "    return n_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data_path= '../data/raw/Updated_data/ACE_data/'\n",
    "files =  list_of_files(data_path)\n",
    "nullfiles = []\n",
    "n = 0\n",
    "for f in files:\n",
    "    df = load_csv(f)\n",
    "    if df.isnull().any().any():\n",
    "        print(f)\n",
    "        nullfiles.append(f)\n",
    "    df, target = pre_process(df)\n",
    "    nu =  check_df(df)\n",
    "    n += nu\n",
    "print( nullfiles)\n",
    "print(n)\n",
    "#check_samples(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863120, 13)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_csv('../data/raw/Updated_data/DSCOVR_Data/combined_csv_DSCOVR_MMS_May_2023_edited.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    target =  df['Delay']\n",
    "    df = df.drop(columns=['time_ti', 'Delay'])\n",
    "    return df, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_all_csv('../data/raw/Updated_data/DSCOVR_Data/')\n",
    "df_Dscovr, target_Dscovr = pre_process(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Dscovr.to_pickle('../data/processed/DSCOVR_X.pkl')\n",
    "target_Dscovr.to_pickle('../data/processed/DSCOVR_Y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=  load_all_csv('../data/raw/Updated_data/ACE_data/')\n",
    "df_ACE, target_ACE =  pre_process(df)\n",
    "df_ACE.to_pickle('../data/processed/ACE_X.pkl')\n",
    "target_ACE.to_pickle('../data/processed/ACE_Y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ACE.shape\n",
    "target_Y = target_ACE.groupby(np.arange(len(df))//80).unique()\n",
    "target_Y.to_pickle('../data/processed/ACE_Y_mean.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Y = target_ACE.groupby(np.arange(len(df))//80).unique()\n",
    "target_Y = get_meandf(target_ACE)\n",
    "target_Y.to_pickle('../data/processed/ACE_Y_mean2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meandf(df):\n",
    "    n_samples = 80\n",
    "    return df.groupby(np.arange(len(df))//n_samples).mean()\n",
    "\n",
    "mean_ACE =  get_meandf(df_ACE)\n",
    "mean_ACE.to_pickle('../data/processed/mean_ACE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22300, 11), (22300,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
